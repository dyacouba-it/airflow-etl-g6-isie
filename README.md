# Transformation de Donn√©es avec Apache Airflow

**Projet M1 IBAM 2025 - Groupe 6 - Exercice 14**

Pipeline ETL (Extract, Transform, Load) enti√®rement automatis√© orchestr√© par Apache Airflow, permettant la synchronisation de donn√©es depuis trois sources diff√©rentes (fichier CSV, base MySQL, base PostgreSQL) vers une base PostgreSQL cible unifi√©e, avec une interface web Flask moderne et un monitoring en temps r√©el via Prometheus et Grafana.

---

## Table des mati√®res

- [Aper√ßu du projet](#aper√ßu-du-projet)
- [Architecture technique](#architecture-technique)
- [Fonctionnalit√©s](#fonctionnalit√©s)
- [Pr√©requis](#pr√©requis)
- [Installation rapide](#installation-rapide)
- [Sc√©nario de test](#-sc√©nario-de-test-complet)
- [Guide d'utilisation](#guide-dutilisation)
- [Monitoring et visualisation](#monitoring-et-visualisation)
- [Commandes de v√©rification](#commandes-de-v√©rification)
- [Maintenance](#maintenance)
- [Structure du projet](#structure-du-projet)
- [Technologies utilis√©es](#technologies-utilis√©es)
- [D√©pannage](#d√©pannage)
- [Points forts et d√©passements](#Points-forts-et-d√©passements)
- [Auteurs](#auteurs)

---

## Aper√ßu du projet

### Objectif

D√©velopper une solution ETL professionnelle qui :
- Extrait automatiquement des donn√©es depuis 3 sources h√©t√©rog√®nes
- Transforme et nettoie les donn√©es (normalisation, d√©duplication)
- D√©tecte intelligemment les changements (INSERT vs UPDATE)
- Synchronise vers une base de donn√©es unifi√©e
- Valide l'int√©grit√© des donn√©es apr√®s chaque ex√©cution
- Fournit une interface web moderne pour la gestion et le monitoring
- Offre un monitoring en temps r√©el des performances

### Cas d'usage

Ce projet r√©pond aux besoins d'entreprises ayant :
- Des donn√©es d'employ√©s dispers√©es dans plusieurs syst√®mes
- Un besoin de centralisation pour l'analyse et le reporting
- Des contraintes de synchronisation quotidienne
- Des exigences de tra√ßabilit√© et d'audit

### R√©sultats attendus

Apr√®s d√©marrage, le syst√®me :
- Synchronise automatiquement **37 employ√©s burkinab√®** depuis 3 sources
- S'ex√©cute quotidiennement √† minuit (@daily)
- Maintient l'int√©grit√© des donn√©es avec validation
- Fournit une interface web Flask interactive
- Affiche les m√©triques en temps r√©el sur Grafana

---

## Architecture technique

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      SOURCES DE DONN√âES                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Fichier CSV     ‚îÇ   MySQL Source   ‚îÇ  PostgreSQL Source       ‚îÇ
‚îÇ  (22 employ√©s)   ‚îÇ   (8 employ√©s)   ‚îÇ   (7 employ√©s)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                  ‚îÇ                    ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                        ____|____
                        |       |
                        |       |
________________________|       |
|                               |
|                               |
|                               |
|                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ----‚ñº‚îÄ‚îÄ-‚îÄ‚îÄ‚îê
|                    ‚îÇ Apache Airflow ‚îÇ
|                    ‚îÇ   Scheduler    ‚îÇ
|                    ‚îÇ    (ETL Core)  ‚îÇ
|                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
|                            ‚îÇ
|      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
|      ‚îÇ                     ‚îÇ                    ‚îÇ
|  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
|  ‚îÇ Extract ‚îÇ          ‚îÇTransform ‚îÇ         ‚îÇ  Load   ‚îÇ
|  ‚îÇParallel ‚îÇ   ‚îÄ‚Üí     ‚îÇ & Clean  ‚îÇ   ‚îÄ‚Üí    ‚îÇ & Sync  ‚îÇ
|  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
|                                                 ‚îÇ
|                                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
|                                       ‚îÇ PostgreSQL Target  ‚îÇ
|                                       ‚îÇ(employes_unified)  ‚îÇ
|                                       ‚îÇ   37‚Üí38 employ√©s   ‚îÇ
|                                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
|                                                 ‚îÇ
|                             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
|                             ‚îÇ                   ‚îÇ                  ‚îÇ
|                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
|                       ‚îÇ   Flask   ‚îÇ      ‚îÇ Prometheus  ‚îÇ    ‚îÇ   Grafana   ‚îÇ
|_______________________‚îÇ  Web App  ‚îÇ      ‚îÇ (M√©triques) ‚îÇ    ‚îÇ (Dashboards)‚îÇ
                        ‚îÇ localhost ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ   :5000   ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     (Interface principale)
```

### Composants principaux

| Composant | R√¥le | Port | Donn√©es |
|-----------|------|------|---------|
| **Flask Web App** | Interface web interactive | 5000 | Dashboard + API REST |
| **Apache Airflow Webserver** | Interface orchestration | 8080 | - |
| **Apache Airflow Scheduler** | Orchestrateur de t√¢ches | - | - |
| **PostgreSQL Source** | Base de donn√©es source | 5432 | 7 employ√©s |
| **MySQL Source** | Base de donn√©es source | 3306 | 8 employ√©s |
| **Fichier CSV** | Fichier source | - | 22 employ√©s |
| **PostgreSQL Target** | Base de donn√©es cible | 5433 | 37 employ√©s (unifi√©s) |
| **Prometheus** | Collecte de m√©triques | 9090 | M√©triques syst√®me |
| **Grafana** | Visualisation | 3000 | Dashboards |

---

## Fonctionnalit√©s

### Interface Web Flask (Nouvelle fonctionnalit√©)

#### Dashboard interactif
- Vue d'ensemble en temps r√©el (37 employ√©s)
- Graphique en donut de r√©partition par source
- KPI (Key Performance Indicators)
- Derni√®re synchronisation affich√©e

#### Gestion des donn√©es
- **Onglet "Base unifi√©e"** : Consultation des donn√©es synchronis√©es
- **Onglet "Employ√©s par source"** : Gestion CRUD par source
  - CSV : Lecture seule
  - MySQL : Create, Read, Update, Delete
  - PostgreSQL : Create, Read, Update, Delete
- **Onglet "Test ETL"** : Formulaires d'ajout rapide
- **Onglet "API"** : Documentation des endpoints REST

#### API REST compl√®te
- `GET /api/stats` - Statistiques globales
- `GET /api/employes` - Liste employ√©s unifi√©s
- `GET /api/sources/{source}/employes` - Employ√©s par source
- `POST /api/sources/{source}/employes` - Ajouter
- `PUT /api/sources/{source}/employes/{id}` - Modifier
- `DELETE /api/sources/{source}/employes/{id}` - Supprimer
- `POST /api/etl/trigger` - D√©clencher l'ETL
- `GET /api/etl/status` - Statut ETL

### Pipeline ETL

#### Extraction parall√®le
- Extraction simultan√©e depuis 3 sources diff√©rentes
- Gestion des erreurs par source ind√©pendante
- Validation des sch√©mas de donn√©es

#### Transformation intelligente
- Normalisation des emails (minuscules, trim)
- Conversion des types de donn√©es
- Nettoyage des doublons (derni√®re occurrence conserv√©e)
- Enrichissement avec m√©tadonn√©es (source, timestamps)

#### Synchronisation diff√©rentielle
- D√©tection automatique INSERT vs UPDATE
- Comparaison par email (cl√© naturelle)
- Mise √† jour uniquement des champs modifi√©s
- Conservation de l'historique avec timestamps

#### Validation post-synchronisation
- V√©rification du nombre d'enregistrements
- Contr√¥le de coh√©rence des donn√©es
- G√©n√©ration de rapports d'ex√©cution

### Automatisation compl√®te

#### Provisioning automatique
- Bases de donn√©es initialis√©es avec 37 employ√©s de test
- Connexions Airflow cr√©√©es automatiquement
- Application Flask d√©marr√©e automatiquement
- Datasource Prometheus configur√© automatiquement
- Dashboard Grafana provisionn√© automatiquement
- DAG activ√© par d√©faut au premier d√©marrage

#### Configuration z√©ro
- Aucune intervention manuelle requise
- D√©marrage en une seule commande (`start.bat`)
- Scripts de maintenance inclus

### Monitoring et observabilit√©

#### M√©triques collect√©es
- Statut des services (up/down)
- Dur√©e d'ex√©cution des t√¢ches ETL
- Nombre d'enregistrements synchronis√©s
- Temps de disponibilit√© (uptime)

#### Dashboards en temps r√©el
- Actualisation automatique toutes les 5 secondes
- Alertes visuelles (rouge/vert)
- Graphiques d'√©volution temporelle
- Interface en fran√ßais

---

## Pr√©requis

### Logiciels requis

#### Docker Desktop
**Version minimale :** 20.10+

**Installation :**
- **Windows** : https://docs.docker.com/desktop/install/windows-install/
  - Activer WSL 2 (Windows Subsystem for Linux)
  - Red√©marrer apr√®s installation
- **macOS** : https://docs.docker.com/desktop/install/mac-install/
- **Linux** : https://docs.docker.com/engine/install/

**V√©rification :**
```cmd
docker --version
docker-compose --version
```

#### Git 
Pour cloner le projet : https://git-scm.com/downloads

### Configuration syst√®me

| Ressource | Minimum | Recommand√© |
|-----------|---------|------------|
| **RAM** | 8 GB | 16 GB |
| **Espace disque** | 10 GB | 20 GB |
| **Processeur** | 4 c≈ìurs | 8 c≈ìurs |
| **Syst√®me d'exploitation** | Windows 10, macOS 10.15, Ubuntu 20.04 | Versions r√©centes |

### Ports requis

Les ports suivants doivent √™tre **disponibles** :
- `3000` - Grafana
- `3306` - MySQL Source
- `5000` - Flask Web App
- `5432` - PostgreSQL Source
- `5433` - PostgreSQL Target
- `8080` - Airflow Webserver
- `9090` - Prometheus

**V√©rifier la disponibilit√© :**
```cmd
netstat -an | findstr "3000 3306 5000 5432 5433 8080 9090"
```

Si un port est occup√©, arr√™tez le service correspondant.

---

## Installation rapide

### M√©thode 1 : Depuis GitHub
```bash
# Cloner le repository
git clone https://github.com/dyacouba-it/airflow-etl-g6-isie.git
cd airflow-etl-g6-isie

# Lancer l'environnement
start.bat  # Windows
# OU
./start.sh  # Linux/macOS
```

### M√©thode 2 : Depuis une archive
```bash
# Extraire l'archive
unzip airflow-etl-g6-isie.zip
cd airflow-etl-g6-isie

# Lancer l'environnement
start.bat  # Windows
```

### Processus de d√©marrage

Le script `start.bat` effectue automatiquement :

1. **V√©rification de Docker** (5 secondes)
2. **Nettoyage des conteneurs existants** (10 secondes)
3. **D√©marrage des conteneurs** (30 secondes)
   - Application Flask
   - 3 bases de donn√©es (MySQL, 2x PostgreSQL)
   - Apache Airflow (webserver + scheduler)
   - Prometheus + Grafana
4. **Initialisation** (120 secondes avec barre de progression)
   - Cr√©ation des tables
   - Insertion des 37 employ√©s de test
   - Configuration d'Airflow
   - Configuration de Grafana
5. **Configuration des connexions Airflow** (10 secondes)
6. **V√©rification de Flask** (10 secondes)

**Dur√©e totale : environ 2 minutes**

### Sortie attendue

```
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                        INSTALLATION TERMIN√âE                            
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

 ACC√àS AUX INTERFACES
 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

  Interface Web
  http://localhost:5000
  ‚Üí Dashboard interactif avec d√©clenchement ETL

  Apache Airflow
  http://localhost:8080
  Identifiants : admin / admin
  ‚Üí Pipeline ETL (DAG "etl_employe_sync" d√©j√† activ√©)

  Prometheus (M√©triques)
  http://localhost:9090
  ‚Üí Collecte de m√©triques syst√®me

  Grafana (Monitoring)
  http://localhost:3000
  Identifiants : admin / admin
  ‚Üí Dashboards de visualisation

 DONN√âES DE TEST : 38 employ√©s (23 CSV + 8 MySQL + 7 PostgreSQL)

 Le projet est pr√™t. Bon test !
```

---


## SC√âNARIO DE TEST COMPLET

> **Cette section d√©crit le sc√©nario de test recommand√© pour d√©montrer le fonctionnement complet du pipeline ETL.**

### Vue d'ensemble

Le sc√©nario se d√©roule en **4 √©tapes** :

1. **V√©rifier l'√©tat initial** (38 employ√©s r√©partis)
2. **Ajouter/Modifier un employ√©** (d√©monstration du CRUD)
3. **Lancer l'ETL** (synchronisation)
4. **V√©rifier la synchronisation** (38 employ√©s synchronis√©s)

**Dur√©e totale : 5 minutes**

---

### √âTAPE 1 : V√©rifier l'√©tat initial

#### Via l'interface Flask

```
1. Ouvrir http://localhost:5000
2. Observer le dashboard :
   ‚Ä¢ Total : 38 employ√©s
   ‚Ä¢ R√©partition : 23 CSV + 8 MySQL + 7 PostgreSQL
   ‚Ä¢ Graphique en donut montrant la distribution
```

#### Via la ligne de commande

```bash
# V√©rifier via l'API
curl http://localhost:5000/api/stats

# V√©rifier la source CSV
type data\data.csv

# V√©rifier la source MySQL
docker exec mysql-source mysql -u mysqluser -pmysqlpass source_db \
  -e "SELECT COUNT(*) AS total FROM employes_mysql;"
# R√©sultat attendu : 8

# V√©rifier la source PostgreSQL
docker exec postgres-source psql -U sourceuser -d source_db \
  -c "SELECT COUNT(*) AS total FROM employes_source;"
# R√©sultat attendu : 7

# V√©rifier la base unifi√©e
docker exec postgres-target psql -U targetuser -d target_db \
  -c "SELECT COUNT(*) AS total FROM employes_unified;"
# R√©sultat attendu : 37
```

**√âtat initial confirm√© : 38 employ√©s (23 + 8 + 7)**

---

### √âTAPE 2 : Ajouter ou modifier un employ√©

#### Option A : Via l'interface Flask

```
1. Aller sur l'onglet "Test ETL"
2. Remplir le formulaire MySQL ou PostgreSQL :
   ‚Ä¢ Nom : Test Professeur
   ‚Ä¢ Email : prof@test.bf
   ‚Ä¢ D√©partement : √âvaluation
   ‚Ä¢ Salaire : 950000
   ‚Ä¢ Date d'embauche : 25-11-2025
3. Cliquer sur "Ajouter dans MySQL"
4. Observer le message de succ√®s
5. Observer : Le compteur MySQL augmente imm√©diatement (8 ‚Üí 9)
```

#### Option B : Via la ligne de commande

```bash
# Ajouter un employ√© dans MySQL
docker exec mysql-source mysql -u mysqluser -pmysqlpass source_db -e \
  "INSERT INTO employes_mysql (nom, email, departement, salaire, date_embauche) \
   VALUES ('Test Professeur', 'prof@test.bf', '√âvaluation', 950000, '2025-11-25');"

# V√©rifier l'ajout
docker exec mysql-source mysql -u mysqluser -pmysqlpass source_db \
  -e "SELECT COUNT(*) FROM employes_mysql;"
# R√©sultat attendu : 9 (√©tait 8)
```

#### Option C : Modifier un employ√© existant

```
1. Aller sur l'onglet "Employ√©s par source"
2. S√©lectionner "MySQL" ou "PostgreSQL"
3. Cliquer sur "Modifier" pour un employ√©
4. Changer le salaire (ex: +100000 FCFA)
5. Enregistrer
6. Observer la modification imm√©diate dans la source
```

**V√©rification importante :**

```bash
# La base unifi√©e N'A PAS encore chang√©
docker exec postgres-target psql -U targetuser -d target_db \
  -c "SELECT COUNT(*) FROM employes_unified;"
# R√©sultat : 38 (inchang√©)

# Cela prouve que la synchronisation n'est PAS automatique
```

---

### √âTAPE 3 : Lancer l'ETL

#### Via l'interface Flask

```
1. Cliquer sur "Lancer ETL" (bouton principal en haut)
2. Observer le message : "ETL d√©clench√© avec succ√®s"
3. Observer : Barre de progression ou message "Synchronisation en cours..."
4. Attendre 15 secondes
5. Observer le message : "Synchronisation termin√©e !"
6. Observer : Les compteurs se mettent √† jour automatiquement
   ‚Ä¢ Total : 38 ‚Üí 39
   ‚Ä¢ MySQL : 8 ‚Üí 9
   ‚Ä¢ Le graphique se met √† jour 
```

#### Alternative : Via Apache Airflow

```
1. Ouvrir http://localhost:8080
2. Se connecter : admin / admin
3. Trouver le DAG "etl_employe_sync"
4. Cliquer sur le bouton ‚ñ∂ (Trigger DAG)
5. Aller dans "Graph View"
6. Observer l'ex√©cution en temps r√©el
   ‚Ä¢ extract_csv ‚Üí vert
   ‚Ä¢ extract_mysql ‚Üí vert
   ‚Ä¢ extract_postgresql ‚Üí vert
   ‚Ä¢ transform_clean ‚Üí vert
   ‚Ä¢ load_to_target ‚Üí vert
   ‚Ä¢ validate_sync ‚Üí vert
7. Toutes les t√¢ches deviennent vertes = succ√®s
```

**Dur√©e : 15 secondes**

---

### √âTAPE 4 : V√©rifier la synchronisation

#### Via l'interface Flask

```
1. Retourner sur l'onglet "Tableau de bord"
2. Observer :
   ‚Ä¢ Total = 39 employ√©s (38 + 1) 
   ‚Ä¢ MySQL = 9 employ√©s (8 + 1) 
   ‚Ä¢ Graphique mis √† jour 
3. Aller sur l'onglet "Base unifi√©e"
4. Observer : Le nouvel employ√© "Test Professeur" appara√Æt dans la liste 
```

#### Via la ligne de commande

```bash
# Compteur total
docker exec postgres-target psql -U targetuser -d target_db \
  -c "SELECT COUNT(*) FROM employes_unified;"
# R√©sultat : 39 (√©tait 38) 

# Trouver le nouvel employ√©
docker exec postgres-target psql -U targetuser -d target_db \
  -c "SELECT id, nom, email, source FROM employes_unified WHERE nom LIKE '%Professeur%';"
# R√©sultat attendu :
#  id |       nom       |      email      | source
# ----+-----------------+-----------------+--------
#  38 | Test Professeur | prof@test.bf    | MySQL

# V√©rifier la r√©partition par source
docker exec postgres-target psql -U targetuser -d target_db \
  -c "SELECT source, COUNT(*) FROM employes_unified GROUP BY source ORDER BY source;"
# R√©sultat attendu :
#    source    | count
# -------------+-------
#  CSV         |    23
#  MySQL       |     9    ‚Üê √©tait 8
#  PostgreSQL  |     7
```

**SYNCHRONISATION R√âUSSIE !**

---

### R√©sum√© du sc√©nario

  √âtape               | √âtat MySQL     | √âtat Base Unifi√©e      | Action    |
|-------|-------------|----------------|------------------------------------|
| **1. √âtat initial** | 8 employ√©s     | 38 employ√©s            | V√©rifier  |
| **2. Ajout**        | 9 employ√©s (+1)| 38 employ√©s (inchang√©) |  Ajouter  |
| **3. ETL**          | 9 employ√©s     | En synchronisation...  | Lancer    |
| **4. Apr√®s ETL**    | 9 employ√©s     | 39 employ√©s (+1)       | V√©rifier  |

### Ce que prouve ce sc√©nario

1. Les sources sont **ind√©pendantes** (MySQL, PostgreSQL)
2. On peut **ajouter/modifier** des donn√©es dans les sources
3. L'ETL **d√©tecte les changements**
4. La synchronisation **fonctionne correctement**
5. La **tra√ßabilit√©** est assur√©e (colonne `source`)
6. Le syst√®me est **complet et op√©rationnel**

---


## Guide d'utilisation

### D√©marrage rapide (2 minutes)

```bash
# Windows
start.bat

# Linux/macOS
./start.sh
```

### Interface Flask (RECOMMAND√âE)

#### Premier acc√®s

```
1. Ouvrir http://localhost:5000
2. Explorer le dashboard :
   ‚Ä¢ KPI avec 37 employ√©s
   ‚Ä¢ Graphique de r√©partition
   ‚Ä¢ Derni√®re synchronisation
```

#### D√©clencher l'ETL

```
1. Cliquer sur le bouton "Lancer ETL" (en haut)
2. Attendre 15 secondes
3. Observer les compteurs se mettre √† jour
4. Message de succ√®s : "Synchronisation termin√©e !"
```

#### Ajouter un employ√©

```
1. Aller sur l'onglet "Test ETL"
2. Choisir MySQL ou PostgreSQL
3. Remplir le formulaire
4. Cliquer sur "Ajouter"
5. Lancer l'ETL pour synchroniser
```

#### Modifier/Supprimer un employ√©

```
1. Aller sur l'onglet "Employ√©s par source"
2. S√©lectionner MySQL ou PostgreSQL
3. Cliquer sur "Modifier" ou "Supprimer"
4. Lancer l'ETL pour synchroniser
```

### Interface Airflow (Alternative)

#### Premier acc√®s

```
1. Ouvrir http://localhost:8080
2. Se connecter : admin / admin
3. Le DAG "etl_employe_sync" est d√©j√† ACTIV√â (toggle bleu)
```

#### D√©clencher manuellement

```
1. Cliquer sur le bouton ‚ñ∂ (Trigger DAG)
2. Aller dans "Graph View"
3. Observer l'ex√©cution (toutes les t√¢ches deviennent vertes)
4. Dur√©e : ~15 secondes
```

#### Comprendre le Graph View

```
extract_csv          ‚îÄ‚îÄ‚îê
extract_mysql        ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚Üí transform_clean ‚îÄ‚îÄ‚Üí load_to_target ‚îÄ‚îÄ‚Üí validate_sync
extract_postgresql   ‚îÄ‚îÄ‚îò

‚Ä¢ Vert = Succ√®s
‚Ä¢ Rouge = √âchec
‚Ä¢ Orange = En cours
‚Ä¢ Bleu fonc√© = Pas encore ex√©cut√©
```

---

## Monitoring et visualisation

### Grafana

#### Acc√®s

```
URL : http://localhost:3000
Identifiants : admin / admin
```

#### Dashboard pr√©-configur√©

Le dashboard "Monitoring ETL Airflow" affiche :
- **Service Status** : √âtat de Prometheus (Up/Down)
- **Scrape Duration** : Temps de collecte des m√©triques
- **Samples Scraped** : Nombre d'√©chantillons par seconde
- **Uptime** : Dur√©e de fonctionnement

Actualisation : Automatique toutes les 5 secondes

### Prometheus

#### Acc√®s

```
URL : http://localhost:9090
```

#### M√©triques disponibles

- `up` : √âtat des services (1 = up, 0 = down)
- `prometheus_target_scrapes_total` : Nombre total de collectes
- `prometheus_target_scrape_duration_seconds` : Dur√©e des collectes

---

## Commandes de v√©rification

### Via l'API Flask

```bash
# Statistiques globales
curl http://localhost:5000/api/stats

# Liste des employ√©s unifi√©s
curl http://localhost:5000/api/employes

# Employ√©s d'une source
curl http://localhost:5000/api/sources/mysql/employes

# D√©clencher l'ETL
curl -X POST http://localhost:5000/api/etl/trigger
```

### Via les bases de donn√©es

#### Source CSV

```bash
# Windows
type data\data.csv

# Linux/macOS
cat data/data.csv
```

#### Source MySQL

```bash
# Compter les employ√©s
docker exec mysql-source mysql -u mysqluser -pmysqlpass source_db \
  -e "SELECT COUNT(*) AS total FROM employes_mysql;"

# Afficher les employ√©s
docker exec mysql-source mysql -u mysqluser -pmysqlpass source_db \
  -e "SELECT * FROM employes_mysql;"
```

#### Source PostgreSQL

```bash
# Compter les employ√©s
docker exec postgres-source psql -U sourceuser -d source_db \
  -c "SELECT COUNT(*) AS total FROM employes_source;"

# Afficher les employ√©s
docker exec postgres-source psql -U sourceuser -d source_db \
  -c "SELECT * FROM employes_source;"
```

#### Base unifi√©e (Target)

```bash
# Compter les employ√©s
docker exec postgres-target psql -U targetuser -d target_db \
  -c "SELECT COUNT(*) AS total FROM employes_unified;"

# R√©partition par source
docker exec postgres-target psql -U targetuser -d target_db \
  -c "SELECT source, COUNT(*) FROM employes_unified GROUP BY source ORDER BY source;"

# Afficher tous les employ√©s avec leur source
docker exec postgres-target psql -U targetuser -d target_db \
  -c "SELECT id, nom, email, source FROM employes_unified ORDER BY source, nom;"

# Chercher un employ√© sp√©cifique
docker exec postgres-target psql -U targetuser -d target_db \
  -c "SELECT * FROM employes_unified WHERE nom LIKE '%Ouedraogo%';"
```

### V√©rifier les services Docker

```bash
# √âtat de tous les conteneurs
docker-compose ps

# Logs de Flask
docker logs flask-app --tail 50

# Logs d'Airflow
docker logs airflow-scheduler --tail 50

# Ressources utilis√©es
docker stats

# Sant√© des conteneurs
docker ps --format "table {{.Names}}\t{{.Status}}"
```

---

## Maintenance

### Scripts disponibles

#### start.bat
D√©marre tout l'environnement (premi√®re installation ou red√©marrage)
```cmd
start.bat
```

#### stop.bat
Arr√™te tous les conteneurs proprement
```cmd
stop.bat
```

#### clean.bat
Supprime tous les conteneurs, volumes et images
```cmd
clean.bat
```

#### verify.bat
V√©rifie que les donn√©es sont correctement synchronis√©es
```cmd
verify.bat
```

### Commandes utiles

```bash
# Red√©marrer un service sp√©cifique
docker-compose restart flask-app

# Voir les logs en temps r√©el
docker-compose logs -f flask-app

# Reconstruire un conteneur
docker-compose up -d --build flask-app

# Nettoyer les ressources Docker inutilis√©es
docker system prune -a

# Sauvegarder les donn√©es
docker exec postgres-target pg_dump -U targetuser target_db > backup.sql

# Restaurer les donn√©es
cat backup.sql | docker exec -i postgres-target psql -U targetuser -d target_db
```

---

## Structure du projet

```
airflow-etl-g6-isie/
‚îÇ
‚îú‚îÄ‚îÄ dags/                          # DAGs Apache Airflow
‚îÇ   ‚îî‚îÄ‚îÄ etl_sync_dag.py           # Pipeline ETL principal
‚îÇ
‚îú‚îÄ‚îÄ backend/                       # Application Flask
‚îÇ   ‚îú‚îÄ‚îÄ app.py                    # Point d'entr√©e Flask
‚îÇ   ‚îú‚îÄ‚îÄ routes/                   # Endpoints API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stats.py             # Statistiques
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ employes.py          # Employ√©s unifi√©s
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sources.py           # Sources de donn√©es
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ etl.py               # D√©clenchement ETL
‚îÇ   ‚îú‚îÄ‚îÄ services/                # Logique m√©tier
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py          # Connexions DB
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ airflow.py           # Client Airflow
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt         # D√©pendances Python
‚îÇ
‚îú‚îÄ‚îÄ frontend/                      # Interface web
‚îÇ   ‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ css/                 # Styles
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variables.css    # Variables CSS
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.css        # Styles de base
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.css      # Mise en page
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components.css  # Composants
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ responsive.css  # Responsive
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ js/                  # Scripts
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ config.js        # Configuration
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ api.js          # Client API
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ ui.js           # Gestion UI
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ charts.js       # Graphiques
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ employees.js    # Gestion employ√©s
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ etl.js          # Gestion ETL
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ main.js         # Point d'entr√©e
‚îÇ   ‚îî‚îÄ‚îÄ templates/
‚îÇ       ‚îî‚îÄ‚îÄ index.html           # Page principale
‚îÇ
‚îú‚îÄ‚îÄ data/                          # Donn√©es sources
‚îÇ   ‚îî‚îÄ‚îÄ data.csv                  # 22 employ√©s CSV
‚îÇ
‚îú‚îÄ‚îÄ init-scripts/                  # Scripts d'initialisation
‚îÇ   ‚îú‚îÄ‚îÄ init-mysql.sql            # Init MySQL (8 employ√©s)
‚îÇ   ‚îî‚îÄ‚îÄ init-postgres-source.sql  # Init PostgreSQL (7 employ√©s)
‚îÇ
‚îú‚îÄ‚îÄ prometheus/                    # Configuration Prometheus
‚îÇ   ‚îî‚îÄ‚îÄ prometheus.yml
‚îÇ
‚îú‚îÄ‚îÄ grafana/                       # Configuration Grafana
‚îÇ   ‚îú‚îÄ‚îÄ provisioning/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ datasources/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prometheus.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dashboards/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ dashboard.yml
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ monitoring-etl.json
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml            # Orchestration Docker
‚îú‚îÄ‚îÄ Dockerfile.flask              # Image Flask
‚îú‚îÄ‚îÄ start.bat                     # Script de d√©marrage Windows
‚îú‚îÄ‚îÄ start.sh                      # Script de d√©marrage Linux/macOS
‚îú‚îÄ‚îÄ stop.bat (stop.sh)            # Script d'arr√™t
‚îú‚îÄ‚îÄ clean.bat (clean.sh)          # Script de nettoyage
‚îú‚îÄ‚îÄ verify.bat (verify.sh)        # Script de v√©rification
‚îî‚îÄ‚îÄ README.md                     # Cette documentation
```

---

## Technologies utilis√©es

### Backend
- **Python 3.11** - Langage principal
- **Apache Airflow 2.7.3** - Orchestration ETL
- **Flask 3.0** - Application web et API REST
- **Pandas 2.0** - Manipulation de donn√©es
- **SQLAlchemy 2.0** - ORM

### Bases de donn√©es
- **PostgreSQL 15** - Base source et cible
- **MySQL 8.0** - Base source

### Frontend
- **HTML5 / CSS3** - Structure et styles
- **JavaScript (Vanilla)** - Interactivit√©
- **Chart.js** - Visualisations

### Monitoring
- **Prometheus** - Collecte de m√©triques
- **Grafana** - Dashboards

### Infrastructure
- **Docker** - Conteneurisation
- **Docker Compose** - Orchestration

### D√©pendances Python

```python
apache-airflow==2.7.3       # Orchestration
flask==3.0.0                # Framework web
pandas>=2.0.0               # Manipulation de donn√©es
sqlalchemy>=2.0.0           # ORM
pymysql>=1.1.0              # MySQL
psycopg2-binary>=2.9.0      # PostgreSQL
prometheus-client>=0.19.0   # Export m√©triques
requests>=2.31.0            # Client HTTP
python-dotenv>=1.0.0        # Variables d'environnement
```

---

## D√©pannage

### Probl√®mes courants

#### Flask n'est pas accessible

**Sympt√¥mes :**
- http://localhost:5000 ne r√©pond pas
- Message "This site can't be reached"

**Solutions :**
```bash
# V√©rifier si Flask est d√©marr√©
docker ps | findstr flask

# Voir les logs Flask
docker logs flask-app

# Red√©marrer Flask
docker-compose restart flask-app

# V√©rifier le port
netstat -an | findstr ":5000"
```

#### Le DAG n'appara√Æt pas dans Airflow

**Causes possibles :**
- Le scheduler n'a pas encore scann√© le dossier `dags/`
- Erreur de syntaxe dans le fichier Python

**Solutions :**
```bash
# V√©rifier les logs du scheduler
docker logs airflow-scheduler --tail 50

# Red√©marrer le scheduler
docker-compose restart airflow-scheduler

# Attendre 30 secondes puis rafra√Æchir Airflow
```

#### Les donn√©es ne se synchronisent pas

**V√©rifications :**
1. Le DAG est-il activ√© ? (toggle bleu dans Airflow)
2. Le DAG s'est-il ex√©cut√© ? (v√©rifier dans Grid view)
3. Toutes les t√¢ches sont-elles vertes ?
4. Y a-t-il des erreurs dans les logs ?

**Solutions :**
```bash
# V√©rifier les logs de la t√¢che load_to_target
# Dans Airflow : DAG ‚Üí T√¢che ‚Üí Log

# V√©rifier les connexions
docker exec airflow-webserver airflow connections list

# V√©rifier les donn√©es dans les sources
docker exec mysql-source mysql -u mysqluser -pmysqlpass source_db \
  -e "SELECT COUNT(*) FROM employes_mysql;"
```

#### Erreur "port already in use"

**Cause :** Un autre service utilise le port.

**Solutions :**
```bash
# Identifier le processus
netstat -ano | findstr ":5000"
netstat -ano | findstr ":8080"

# Arr√™ter le processus (Windows)
taskkill /PID <PID> /F

# OU modifier le port dans docker-compose.yml
ports:
  - "5001:5000"  # Utiliser 5001 au lieu de 5000
```

#### Grafana affiche "No data"

**Causes possibles :**
- Prometheus non connect√©
- Datasource non configur√©
- Requ√™te Prometheus invalide

**Solutions :**
```bash
# V√©rifier Prometheus
curl http://localhost:9090/-/healthy

# Tester une requ√™te
curl "http://localhost:9090/api/v1/query?query=up"

# Dans Grafana
# Configuration ‚Üí Data sources ‚Üí Prometheus ‚Üí Test
```

#### L'ajout d'employ√© √©choue

**Sympt√¥mes :**
- Message d'erreur dans Flask
- L'employ√© n'appara√Æt pas dans la source

**Solutions :**
```bash
# V√©rifier les logs Flask
docker logs flask-app --tail 50

# V√©rifier la connexion √† la base
docker exec mysql-source mysql -u mysqluser -pmysqlpass -e "SELECT 1;"

# V√©rifier les donn√©es dans le formulaire (champs requis)
```

### Commandes de diagnostic

```bash
# √âtat de tous les services
docker-compose ps

# Logs de tous les services
docker-compose logs --tail=50

# Logs d'un service sp√©cifique
docker logs <nom-conteneur> --tail 100 -f

# Ressources utilis√©es
docker stats

# Espace disque
docker system df

# Sant√© des conteneurs
docker ps --format "table {{.Names}}\t{{.Status}}"

# Nettoyer les ressources inutilis√©es
docker system prune -a
```

---

## Points forts et d√©passements

### Points forts du projet

**Automatisation totale (100%)**
- Z√©ro configuration manuelle requise
- Provisioning automatique de tous les composants
- DAG activ√© par d√©faut au d√©marrage
- Scripts de maintenance complets

**Interface web moderne**
- Application Flask avec dashboard interactif
- API REST compl√®te (10+ endpoints)
- CRUD complet sur MySQL et PostgreSQL
- Design professionnel et responsive

**Architecture professionnelle**
- 9 conteneurs Docker orchestr√©s
- S√©paration claire des environnements (source/target)
- Frontend modulaire (8 fichiers JS)
- Backend structur√© (routes + services)

**Pipeline ETL robuste**
- Extraction parall√®le depuis 3 sources h√©t√©rog√®nes
- Transformation avec nettoyage et validation
- Synchronisation diff√©rentielle (INSERT/UPDATE)
- Gestion d'erreurs par source
- 37 employ√©s burkinab√® synchronis√©s

**Observabilit√© compl√®te**
- M√©triques Prometheus en temps r√©el
- Dashboards Grafana en fran√ßais
- Logs d√©taill√©s pour chaque t√¢che
- Validation automatique post-ex√©cution

**Documentation exhaustive**
- README de 1000+ lignes
- Sc√©nario de test d√©taill√© en 4 √©tapes
- Guide d'utilisation complet
- Commandes de v√©rification pour toutes les sources

**Reproductibilit√© garantie**
- Fonctionne sur Windows, macOS, Linux
- Environnement isol√© dans Docker
- Versions fixes des d√©pendances
- Temps de d√©marrage pr√©visible (~2 min)

### D√©passement des attentes

Le projet va au-del√† de l'exercice 14 en int√©grant :
- Interface web Flask moderne (non demand√©e)
- API REST compl√®te (10+ endpoints)
- CRUD complet sur les sources
- Provisioning automatique (Grafana, Prometheus)
- Dashboard personnalis√©
- Validation post-ETL
- Scripts de maintenance
- Documentation niveau production

### D√©monstration recommand√©e

**Dur√©e totale : 5 minutes**

#### 1. D√©marrage (30 secondes)
```
‚Ä¢ Ex√©cuter start.bat
‚Ä¢ Montrer la barre de progression
‚Ä¢ Attendre le message "Installation termin√©e"
```

#### 2. Interface Flask (2 minutes)
```
‚Ä¢ Ouvrir http://localhost:5000
‚Ä¢ Montrer le dashboard avec 37 employ√©s
‚Ä¢ Aller sur "Test ETL"
‚Ä¢ Ajouter un employ√© (Test Professeur)
‚Ä¢ Observer : Compteur MySQL passe de 8 ‚Üí 9
‚Ä¢ Cliquer sur "Lancer ETL"
‚Ä¢ Attendre 15 secondes
‚Ä¢ Observer : Total passe de 37 ‚Üí 38
‚Ä¢ Aller sur "Base unifi√©e"
‚Ä¢ Montrer "Test Professeur" synchronis√©
```

#### 3. V√©rification ligne de commande (1 minute)
```bash
# Montrer la r√©partition
docker exec postgres-target psql -U targetuser -d target_db \
  -c "SELECT source, COUNT(*) FROM employes_unified GROUP BY source;"

# CSV: 22, MySQL: 9 (√©tait 8), PostgreSQL: 7
```

#### 4. Airflow (1 minute)
```
‚Ä¢ Ouvrir http://localhost:8080 (admin/admin)
‚Ä¢ Montrer le DAG d√©j√† activ√©
‚Ä¢ Montrer le Graph View avec toutes les t√¢ches vertes
‚Ä¢ Expliquer le pipeline Extract ‚Üí Transform ‚Üí Load
```

#### 5. Monitoring (30 secondes)
```
‚Ä¢ Ouvrir Grafana http://localhost:3000 (admin/admin)
‚Ä¢ Montrer le dashboard en fran√ßais
‚Ä¢ Expliquer les m√©triques Prometheus
```

**Points √† souligner :**
- 0 configuration manuelle
- Interface web moderne
- CRUD complet
- Synchronisation automatique
- Tra√ßabilit√© (colonne `source`)
- Documentation compl√®te

---

## üë• Auteurs

**Projet M1 IBAM 2025 - Groupe 6**

### Membres du groupe

- [DAO Yacouba]
- [DA Sansan Nilce]
- [KABORE Kiswendsida In√®s Odette]
- [SAWADOGO Jo√´lle Anisaah]


### Encadrement

- **Professeur :** [Fadel GUY]
- **Institution :** IBAM - Institut Burkinab√® des Arts et M√©tiers
- **Ann√©e acad√©mique :** 2024-2025
- **Module :** D√©veloppement √† Base de Composants et Services Web

### Contexte acad√©mique

**Exercice 14 :** Transformation de Donn√©es avec Apache Airflow

**Objectif :** Apprendre √† utiliser Apache Airflow pour orchestrer un workflow ETL de
transformation de donn√©es.

**T√¢che :** Cr√©er un workflow Airflow pour extraire des donn√©es d‚Äôun ficher csv et de deux
bases de donn√©es source (Mysql, Postgresql), les transformer, et les charger dans une autre
base de donn√©es (Postgresql).
- Installez et configurez Apache Airflow.
- Connectez-vous aux bases de donn√©es source et cible.
- Cr√©ez une transformation pour extraire les donn√©es de la base de donn√©es
source.
- Ajoutez des √©tapes de comparaison et de mise √† jour pour synchroniser les
donn√©es dans la base de donn√©es cible.
- V√©rifiez les r√©sultats dans la base de donn√©es cible.
- Observer les m√©triques sur Grafana

---

## Licence

Projet acad√©mique - Groupe 6 - ISIE IBAM 2025

---

## Support

Pour toute question concernant ce projet :

- **Issues GitHub :** https://github.com/dyacouba-it/airflow-etl-g6-isie/issues
- **Email :** [yacouba.info@gmail.com]
- **Documentation Airflow :** https://airflow.apache.org/docs/
- **Documentation Flask :** https://flask.palletsprojects.com/
- **Documentation Docker :** https://docs.docker.com/

---

## Am√©liorations futures

### V2.0 (suggestions)

- [ ] Support de sources suppl√©mentaires (API REST)
- [ ] Gestion des donn√©es sensibles (secrets vault)
- [ ] Clustering Airflow pour haute disponibilit√©
- [ ] Authentification utilisateurs

---

**Derni√®re mise √† jour :** Novembre 2025  
**Version :** 1.0.0  
**Statut :** Production-ready
